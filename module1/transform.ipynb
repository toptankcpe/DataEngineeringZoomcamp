{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\de2025\\zoomcamp\\module1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\de2025\\zoomcamp\\module1\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 5.0/25.2 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.2 MB 60.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 55.1 MB/s eta 0:00:00\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-extensions, pyarrow, psycopg2, numpy, greenlet, sqlalchemy, pandas\n",
      "Successfully installed greenlet-3.1.1 numpy-2.2.1 pandas-2.2.3 psycopg2-2.9.10 pyarrow-19.0.0 pytz-2024.2 sqlalchemy-2.0.37 typing-extensions-4.12.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy psycopg2 pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys\n",
    "from time import time\n",
    "import pandas as pd \n",
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"root\"\n",
    "password = \"root\"\n",
    "host = \"pgdatabase\"\n",
    "port = \"5432\"\n",
    "db = \"ny_taxi\"\n",
    "tb_main = \"green_tripdata\"\n",
    "tb_lookup = \"taxi_zone\"\n",
    "url_main = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\"\n",
    "url_lookup = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
    "save_path = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = url_main.rsplit('/', 1)[-1].strip()\n",
    "full_path = os.path.join(save_path, file_name)\n",
    "os.system(f\"curl -L {url_main} -o {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topta\\AppData\\Local\\Temp\\ipykernel_26644\\1351154296.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(full_path,index_col=False)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(full_path,index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476386 entries, 0 to 476385\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               387007 non-null  float64\n",
      " 1   lpep_pickup_datetime   476386 non-null  object \n",
      " 2   lpep_dropoff_datetime  476386 non-null  object \n",
      " 3   store_and_fwd_flag     387007 non-null  object \n",
      " 4   RatecodeID             387007 non-null  float64\n",
      " 5   PULocationID           476386 non-null  int64  \n",
      " 6   DOLocationID           476386 non-null  int64  \n",
      " 7   passenger_count        387007 non-null  float64\n",
      " 8   trip_distance          476386 non-null  float64\n",
      " 9   fare_amount            476386 non-null  float64\n",
      " 10  extra                  476386 non-null  float64\n",
      " 11  mta_tax                476386 non-null  float64\n",
      " 12  tip_amount             476386 non-null  float64\n",
      " 13  tolls_amount           476386 non-null  float64\n",
      " 14  ehail_fee              0 non-null       float64\n",
      " 15  improvement_surcharge  476386 non-null  float64\n",
      " 16  total_amount           476386 non-null  float64\n",
      " 17  payment_type           387007 non-null  float64\n",
      " 18  trip_type              387005 non-null  float64\n",
      " 19  congestion_surcharge   387007 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(3)\n",
      "memory usage: 72.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique types in lpep_pickup_datetime: [<class 'str'>]\n",
      "Unique types in lpep_dropoff_datetime: [<class 'str'>]\n",
      "Unique types in store_and_fwd_flag: [<class 'str'> <class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "object_columns = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for col in object_columns:\n",
    "    unique_types = df[col].apply(type).unique()\n",
    "    print(f\"Unique types in {col}: {unique_types}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_values = df[df[\"store_and_fwd_flag\"].apply(lambda x: isinstance(x, str))]\n",
    "str_values[\"store_and_fwd_flag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_values = df[df[\"store_and_fwd_flag\"].apply(lambda x: isinstance(x, float))]\n",
    "float_values['store_and_fwd_flag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(full_path,index_col=False,terator=True, chunksize=100000)\n",
    "while True: \n",
    "    try:\n",
    "        t_start = time()\n",
    "\n",
    "        if file_name == \"green_tripdata_2019-10.csv.gz\":\n",
    "            df = next(df_iter)\n",
    "            df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "            df[\"lpep_dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "            df.to_sql(name=tb_main, con=engine, if_exists='replace')\n",
    "        elif file_name == \"taxi_zone_lookup.csv\":\n",
    "            df = next(df_iter)\n",
    "            file_name == \"green_tripdata_2019-10.csv.gz\"\n",
    "            df.to_sql(name=tb_lookup, con=engine, if_exists='replace')\n",
    "\n",
    "        t_end = time()\n",
    "\n",
    "        print('inserted another chunk, took %.3f second' % (t_end - t_start))\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"Finished ingesting data into the postgres database\")\n",
    "        break\n",
    "\n",
    "\n",
    "df.to_sql(name=tb_main,con=engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'store_and_fwd_flag' is string:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476386 entries, 0 to 476385\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               387007 non-null  float64\n",
      " 1   lpep_pickup_datetime   476386 non-null  object \n",
      " 2   lpep_dropoff_datetime  476386 non-null  object \n",
      " 3   store_and_fwd_flag     387007 non-null  object \n",
      " 4   RatecodeID             387007 non-null  float64\n",
      " 5   PULocationID           476386 non-null  int64  \n",
      " 6   DOLocationID           476386 non-null  int64  \n",
      " 7   passenger_count        387007 non-null  float64\n",
      " 8   trip_distance          476386 non-null  float64\n",
      " 9   fare_amount            476386 non-null  float64\n",
      " 10  extra                  476386 non-null  float64\n",
      " 11  mta_tax                476386 non-null  float64\n",
      " 12  tip_amount             476386 non-null  float64\n",
      " 13  tolls_amount           476386 non-null  float64\n",
      " 14  ehail_fee              0 non-null       float64\n",
      " 15  improvement_surcharge  476386 non-null  float64\n",
      " 16  total_amount           476386 non-null  float64\n",
      " 17  payment_type           387007 non-null  float64\n",
      " 18  trip_type              387005 non-null  float64\n",
      " 19  congestion_surcharge   387007 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(3)\n",
      "memory usage: 72.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "\n",
    "# Create SQL engine\n",
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{db}')\n",
    "\n",
    "file = pq.ParquetFile(file_name)\n",
    "df = next(file.iter_batches(batch_size=10)).to_pandas()\n",
    "df_iter = file.iter_batches(batch_size=100000)\n",
    "\n",
    "# Create the table\n",
    "df.head(0).to_sql(name=tb, con=engine, if_exists='replace')\n",
    "\n",
    "# Insert values\n",
    "t_start = time()\n",
    "count = 0\n",
    "for batch in df_iter:\n",
    "    count+=1\n",
    "\n",
    "    batch_df = batch.to_pandas()\n",
    "\n",
    "    print(f'inserting batch {count}...')\n",
    "\n",
    "    b_start = time()\n",
    "    batch_df.to_sql(name=tb, con=engine, if_exists='append')\n",
    "    b_end = time()\n",
    "\n",
    "    print(f'inserted! time taken {b_end-b_start:10.3f} seconds.\\n')\n",
    "    \n",
    "t_end = time()   \n",
    "print(f'Completed! Total time taken was {t_end-t_start:10.3f} seconds for {count} batches.')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
